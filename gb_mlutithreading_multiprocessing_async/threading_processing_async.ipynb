{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concurrency in Python – Fundamental Concepts\n",
    "\n",
    "Python offers several approaches to concurrency, each with its own characteristics and limitations. Understanding the basics—including the Global Interpreter Lock (GIL) and key synchronization primitives—is essential.\n",
    "\n",
    "---\n",
    "\n",
    "## Global Interpreter Lock (GIL)\n",
    "- **What It Is:**  \n",
    "  A mutex that protects access to Python objects, preventing multiple native threads from executing Python bytecodes simultaneously.\n",
    "- **Impact:**  \n",
    "  - **Multithreading:** Limits true parallel execution of CPU-bound Python code, although I/O-bound tasks can benefit.\n",
    "  - **Multiprocessing:** Each process has its own interpreter and GIL, allowing true parallelism on multiple cores.\n",
    "- **Key Point:**  \n",
    "  The GIL means that in CPython, threads don't run in parallel for CPU-bound tasks but can be very effective for I/O-bound operations.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Multithreading\n",
    "- **What It Is:**  \n",
    "  Uses the `threading` module to run multiple threads (lightweight processes) within a single process.\n",
    "  \n",
    "- **Key Points:**  \n",
    "  - Best suited for I/O-bound tasks (e.g., network requests, file I/O) rather than CPU-bound operations due to the Global Interpreter Lock (GIL).\n",
    "  - Threads share the same memory space, which makes communication easier but requires careful synchronization (e.g., locks, semaphores).\n",
    "\n",
    "**Fundamental Concepts:**  \n",
    "  - **Locks:**  \n",
    "    Ensure that only one thread can access a resource at a time. Critical for avoiding race conditions.\n",
    "    ```python\n",
    "    import threading\n",
    "    lock = threading.Lock()\n",
    "    with lock:\n",
    "        # critical section\n",
    "    ```\n",
    "  - **Semaphores:**  \n",
    "    Control access to a shared resource through a counter, allowing a specified number of threads to access a resource concurrently.\n",
    "    ```python\n",
    "    semaphore = threading.Semaphore(3)  # Allows up to 3 threads concurrently.\n",
    "    with semaphore:\n",
    "        # resource access\n",
    "    ```\n",
    "  - **Thread Safety & Synchronization:**  \n",
    "    Using synchronization primitives (locks, events, conditions) to coordinate thread execution and prevent data corruption.\n",
    "- **When to Use:**  \n",
    "  Ideal for I/O-bound tasks (e.g., network I/O, file I/O) where the waiting time allows other threads to run.\n",
    "\n",
    "- **When to Use:**  \n",
    "  For tasks that spend much time waiting (e.g., web scraping, handling I/O), where parallelism improves overall responsiveness.\n",
    "\n",
    "---\n",
    "\n",
    "## Multiprocessing\n",
    "- **What It Is:**  \n",
    "  Uses the `multiprocessing` module to create separate processes, each with its own Python interpreter and memory space.\n",
    "\n",
    "- **Key Points:**  \n",
    "  - Overcomes the GIL, making it ideal for CPU-bound tasks that require true parallelism.\n",
    "  - Processes do not share memory by default, so data exchange is typically handled via inter-process communication (IPC), such as queues or pipes.\n",
    "\n",
    "- **Fundamental Concepts:**  \n",
    "  - **Process Creation:**  \n",
    "    Each process runs independently and in parallel, circumventing the GIL.\n",
    "  - **Inter-Process Communication (IPC):**  \n",
    "    Mechanisms like queues, pipes, or shared memory are used to exchange data between processes.\n",
    "    ```python\n",
    "    from multiprocessing import Process, Queue\n",
    "    def worker(q):\n",
    "        q.put(\"data\")\n",
    "    q = Queue()\n",
    "    p = Process(target=worker, args=(q,))\n",
    "    p.start()\n",
    "    p.join()\n",
    "    print(q.get())\n",
    "    ```\n",
    "  - **Synchronization:**  \n",
    "    Similar to threading, but using process-safe primitives such as `multiprocessing.Lock` or `multiprocessing.Semaphore`.\n",
    "- **When to Use:**  \n",
    "  For compute-intensive tasks (e.g., data processing, simulations) where parallel execution across multiple cores can significantly boost performance.\n",
    "\n",
    "---\n",
    "\n",
    "## Asynchronous Programming (Async/Await)\n",
    "- **What It Is:**  \n",
    "  Uses the `asyncio` library (and `async`/`await` syntax) to write concurrent code that runs on a single thread via an event loop.\n",
    "\n",
    "- **Key Points:**  \n",
    "  - Ideal for I/O-bound and high-level structured network code, where tasks are frequently waiting for external events.\n",
    "  - Provides non-blocking execution by suspending and resuming tasks as I/O operations complete, rather than using multiple threads or processes.\n",
    "- **Fundamental Concepts:**  \n",
    "  - **Event Loop:**  \n",
    "    The core of async programming that schedules and runs asynchronous tasks.\n",
    "  - **Coroutines:**  \n",
    "    Functions defined with `async def` that can pause their execution with `await` to let other tasks run.\n",
    "    ```python\n",
    "    import asyncio\n",
    "\n",
    "    async def fetch_data():\n",
    "        await asyncio.sleep(1)\n",
    "        return \"data\"\n",
    "\n",
    "    async def main():\n",
    "        data = await fetch_data()\n",
    "        print(data)\n",
    "\n",
    "    asyncio.run(main())\n",
    "    ```\n",
    "  - **Non-Blocking I/O:**  \n",
    "    Instead of waiting (blocking) for I/O operations to complete, async code uses `await` to pause and resume when ready.\n",
    "\n",
    "- **When to Use:**  \n",
    "  For high-concurrency scenarios like handling many simultaneous network connections, real-time data feeds, or web servers where the overhead of threads or processes is undesirable.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "- **Multithreading:**  \n",
    "  Good for I/O-bound tasks; limited by the GIL for CPU-bound tasks.\n",
    "- **Multiprocessing:**  \n",
    "  Provides true parallelism for CPU-bound tasks at the cost of increased memory usage and inter-process communication complexity.\n",
    "- **Asynchronous Programming:**  \n",
    "  Efficiently handles many concurrent I/O operations with minimal overhead, ideal for networked and event-driven applications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import asyncio\n",
    "\n",
    "# async def fetch_data():\n",
    "#     await asyncio.sleep(1)\n",
    "#     return \"data\"\n",
    "\n",
    "# async def main():\n",
    "#     data = await fetch_data()\n",
    "#     print(data)\n",
    "\n",
    "# asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- **GIL:**  \n",
    "  Limits true parallelism in threads for CPU-bound tasks; overcome by multiprocessing.\n",
    "- **Multithreading:**  \n",
    "  Useful for I/O-bound tasks; requires careful use of locks and semaphores to ensure thread safety.\n",
    "- **Multiprocessing:**  \n",
    "  Ideal for CPU-bound tasks with true parallel execution; uses separate memory spaces and IPC for communication.\n",
    "- **Asynchronous Programming:**  \n",
    "  Efficient for handling a large number of concurrent I/O-bound operations using an event loop and coroutines.\n",
    "\n",
    "Each concurrency model has its own strengths and trade-offs, and choosing the right one depends on the specific problem you need to solve."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
